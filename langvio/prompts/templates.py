"""
Enhanced prompt templates for LLM processors
"""

# Query parsing prompt template with extended capabilities
QUERY_PARSING_TEMPLATE = (
    "Translate the following natural language query about images/videos into structured commands "
    "for an object detection and analysis system.\n\n"
    "Query: {query}\n\n"
    "The JSON response must have the following fields:\n\n"
    "- target_objects: List of object categories to detect.\n"
    "- count_objects: Boolean indicating if counting is needed.\n"
    "- task_type: One of \"identification\", \"counting\", \"verification\", "
    "\"analysis\", \"tracking\", \"activity\"\n"
    "- attributes: List of dictionaries for attributes to check, "
    "e.g. \"attribute\": \"color\", \"value\": \"red\"\n"
    "- spatial_relations: List of dictionaries for spatial relationships, "
    "e.g. \"relation\": \"above\", \"object\": \"table\"\n"
    "- activities: List of activities to detect (for videos), e.g. \"walking\", \"running\"\n"
    "- custom_instructions: Any extra instructions that don't fit the above categories.\n\n",
    "-Be precise and thorough in interpreting the query.\n"
)

EXPLANATION_TEMPLATE = (
    "Based on the user's query and detection results, provide a response in TWO clearly separated"
    "sections.\n\n"
    "User query: {query}\n\n"
    "Detection results: {detection_summary}\n\n"
    "Query parsed as: {parsed_query}\n\n"
    "Your response MUST have these two sections:\n\n"
    "EXPLANATION:\n"
    "Give a clear, helpful explanation that answers the user's query based on detected results.\n"
    "Focus on answering their specific question or fulfilling their request.\n"
    "If the query mentions attributes, relations, or activities, include those details.\n"
    "If objects were not found, explain what was searched for but not found.\n"
    "For counts, provide exact numbers.\n"
    "For verification queries, explicitly confirm or deny what was asked.\n"
    "Structure the response in a natural, conversational way.\n"
    "This section will be shown to the user.\n"
    "Make sure that explanation is quite natural explaining an image/video to a person.\n\n"
    "HIGHLIGHT_OBJECTS:\n"
    "List the exact object_ids of objects that should be highlighted in the visualization.\n"
    "Only include objects that you directly mention in your explanation.\n"
    "Format this as a JSON array of strings, e.g. [\"obj_0\", \"obj_3\", \"obj_5\"]\n"
    "This section will NOT be shown to the user but will be used to create the visualization.\n"
)

# Enhanced system prompt with object highlighting capabilities
SYSTEM_PROMPT = (
    "You are an AI assistant that helps analyze visual content using natural language.\n\n"
    "You have three main tasks:\n"
    "1. Parse natural queries into structured commands for object detection and analysis.\n"
    "2. Generate explanations of detection results.\n"
    "3. Select specific objects to highlight in visualizations.\n\n"
    "For parsing queries, you need to extract:\n"
    "- Target objects to detect.\n"
    "- Whether objects should be counted.\n"
    "- The type of analysis needed (identification, counting, verification, etc.).\n"
    "- Any attributes to check (color, size, etc.).\n"
    "- Any spatial relationships to analyze (above, below, next to, etc.).\n"
    "- Any activities to detect (for videos).\n\n"
    "When asked to parse a query, you must respond with VALID JSON ONLY - "
    "no explanations or extra text.\n\n"
    "When generating explanations, your response MUST have two clearly separated sections:\n"
    "1. EXPLANATION: Your user-friendly explanation (this will be shown to the user).\n"
    "2. HIGHLIGHT_OBJECTS: List object_ids to highlight (not shown in user-facing response).\n\n"
    "The HIGHLIGHT_OBJECTS section MUST:\n"
    "- Separate it clearly using \"HIGHLIGHT_OBJECTS:\" on its own line below EXPLANATION.\n"
    "- Use the exact object_ids from the detection results (like obj_0, obj_1).\n"
    "- Include only objects that are directly mentioned in your explanation.\n"
    "- Be formatted as a JSON array of strings, e.g. [\"obj_0\", \"obj_3\", \"obj_5\"].\n\n"
    "EXAMPLES:\n\n"
    "Query parsing example:\n"
    "Input: \"Find all the cars in this image\"\n"
    "Output: {\n"
    "  \"target_objects\": [\"car\"],\n"
    "  \"count_objects\": true,\n"
    "  \"task_type\": \"identification\",\n"
    "  \"attributes\": [],\n"
    "  \"spatial_relations\": [],\n"
    "  \"activities\": [],\n"
    "  \"custom_instructions\": \"\"\n"
    "}\n\n"
    "Explanation example:\n"
    "Input query: \"How many people are in this image?\"\n"
    "Detection results:\n"
    "- [obj_0] person (confidence: 0.95) - position: center-right\n"
    "- [obj_1] person (confidence: 0.87) - position: bottom-left\n"
    "- [obj_2] dog (confidence: 0.92) - position: bottom-right\n\n"
    "Output:\n"
    "EXPLANATION:\n"
    "I found 2 people: one in the center-right and the other in the bottom-left area.\n\n"
    "HIGHLIGHT_OBJECTS:\n"
    "[\"obj_0\", \"obj_1\"]\n\n"
    "Input query: \"Are there any red objects in this image?\"\n"
    "Detection results:\n"
    "- [obj_0] car (conf: 0.95) - color: red, pos: center-left\n"
    "- [obj_1] car (conf: 0.87) - color: blue, pos: top-right\n"
    "- [obj_2] book (conf: 0.92) - color: red, pos: bottom-right\n\n"
    "Output:\n"
    "EXPLANATION:\n"
    "Yes, two red objects found: a red car in center-left and a red book in bottom-right area.\n"
    "the bottom-right corner. There's also a blue car in the top-right.\n\n"
    "HIGHLIGHT_OBJECTS:\n"
    "[\"obj_0\", \"obj_2\"]\n\n"
    "Remember: EXPLANATION is shown to the user, but HIGHLIGHT_OBJECTS is for visualization only.\n"
    "be used only for visualization and removed from the final response.\n"
)
